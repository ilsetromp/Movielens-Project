---
title: "MovieLens Project"
author: "Ilse Tromp"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# MovieLens Project

## Introduction

In this project, the MovieLens dataset will be used to develop an algorithm that can serve as a movie recommendation system with an RMSE that will be as low as possible. MovieLens is a site run by the University of Minnesota. The data set that will be used for this project is the 10M dataset, consisting of 10 million ratings and 100,000 tag applications on 10,000 movies by 72,000 users. 

### Loading the data set

Before we get started we first load some packages.

```r
library(tidyverse)
library(caret)
library(ggplot2)
library(dplyr)
library(lubridate)
```

Now we download the files that contain the data.

```{r, echo = TRUE}
dl <- "ml-10M100K.zip"
if(!file.exists(dl))
  download.file("https://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings_file <- "ml-10M100K/ratings.dat"
if(!file.exists(ratings_file))
  unzip(dl, ratings_file)

movies_file <- "ml-10M100K/movies.dat"
if(!file.exists(movies_file))
  unzip(dl, movies_file)
  ```
Next, we make sure our ratings variable is split into several variables, 
that these columns have the right names, and each variable is correctly defined as integer or numeric.

```{r, echo = TRUE}
ratings <- as.data.frame(str_split(read_lines(ratings_file), fixed("::"), simplify = TRUE),
                         stringsAsFactors = FALSE)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
ratings <- ratings %>%
  mutate(userId = as.integer(userId),
         movieId = as.integer(movieId),
         rating = as.numeric(rating),
         timestamp = as.integer(timestamp))
```

Now, we do the same for the movies variable. Only movieID has to be defined as integer. 

```{r, echo = TRUE}
movies <- as.data.frame(str_split(read_lines(movies_file), fixed("::"), simplify = TRUE),
                        stringsAsFactors = FALSE)
colnames(movies) <- c("movieId", "title", "genres")
movies <- movies %>%
  mutate(movieId = as.integer(movieId))
```

We can combine the data tables containing ratings and movies.

```{r, echo = TRUE}
movielens <- left_join(ratings, movies, by = "movieId")
```

We will split our data set into a training and test set, so we can test in the end how well our algorithm works.

```{r, echo = TRUE}
set.seed(1, sample.kind="Rounding") 
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]
```
Now we make sure this final test set also contains userID and movieID.

```{r, echo = TRUE}
final_holdout_test <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")
  ```
Now, we add the rows back into our edx data set that we removed whilst creating our final test set.

```{r, echo = TRUE}
removed <- anti_join(temp, final_holdout_test)
edx <- rbind(edx, removed)
```

Finally, we transform the timestamp to a date:

```{r, echo=TRUE}
edx <- EDX %>%
mutate(date = as_datetime(timestamp))
```

The edx dataset consists of 9000055 rows and 6 columns. These columns represent the following parameters: userID (for each individual who has rated movies), movieID (an ID for each movie), rating (the rating a movie received from a user), timestamp (time in seconds since 01-01-1970), title (the title of the movie plus the year the movie came out), and genres (to which genres a movie belongs).

During this project, an algorithm will be developed that will estimate the rating (the variable that we would like to predict) based on the movie, genres, and user.

## Exploratory data analysis

We will start with analyzing the data the gain some insights.

The number of movies per genre is:

```{r, echo = FALSE}
genres = c("Drama", "Comedy", "Thriller", "Romance")
sapply(genres, function(g) {
  sum(str_detect(edx$genres, g))
})
```

This treemap is a visualization of the movies per genre:

```{r, echo=FALSE}
ggplot(genre_count, aes(area = count, fill = genres, label = genres)) +
  geom_treemap() +
  geom_treemap_text(colour = "white", place = "centre", grow = TRUE) +
  labs(title = "Treemap of Movie Genres", fill = "Genre") +
  theme_minimal()
```

The most rated movie is:

```{r, echo = FALSE}
edx %>%
  group_by(title) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1)
```

When accounting for ratings, the top ten best rated movies with at least 10,000 ratings are:

```{r, echo = FALSE}
edx %>%
  group_by(title) %>%
  summarize(average_rating = mean(rating), n = n()) %>%
  filter(n >= 10000) %>%
  arrange(desc(average_rating)) %>%
  top_n(10, average_rating)
```

When accounting for ratings, the top ten worst rated movies with at least 10,000 ratings are:

```{r, echo = FALSE}
edx %>%
  group_by(title) %>%
  summarize(average_rating = mean(rating), n = n()) %>%
  filter(n >= 10000) %>%
  arrange(average_rating) %>%
  top_n(-10, average_rating)
```

The distribution of ratings can be viewed in this plot:

```{r, echo = FALSE}
edx %>% ggplot(aes(rating)) +
  geom_histogram(binwidth = 0.5, fill = "blue", color = "black") +
  labs(title = "Distribution of Ratings", x = "Rating", y = "Count")
```

You can see that whole ratings (1, 2, 3, 4, and 5) are given more often than half ratings (0.5, 1.5, 2.5, 3.5, and 4.5).

Average user ratings:

The number of ratings per user can be viewed in this plot:

```{r, echo = FALSE}
edx %>% 
  count(userId) %>%
  ggplot(aes(x = n)) +
  geom_bar(color = "black") +
  labs(title = "Number of Ratings per User", x = "Number of Ratings", y = "Count") +
  scale_x_continuous(trans = "log10")
```

The number of ratings per movie can be viewed in this plot:

```{r, echo = FALSE}
edx %>% 
  count(movieId) %>%
  ggplot(aes(x = n)) +
  geom_bar(color = "black") +
  labs(title = "Number of Ratings per Movie", x = "Number of Ratings", y = "Count") +
  scale_x_continuous(trans = "log10")
```

## Data handling

When checking the data for missing values, 

``` {r, echo is FALSE}
sum(is.na(edx))

colSums(is.na(edx))
```

No missing values are found. So, there is no need to account for missing values.


## Model development

In search for the best possible algorithm, several models will be assessed and evaluated. First, a baseline model will be build to compare the more advanced models to. 

### Baseline model

For this baseline model, the average rating across all movies 

The average rating is:

```{r, echo = FALSE}
mu <- mean(edx$rating)

mu
```

The baseline model has the equation:

$Y = \mu + \varepsilon$

In code this looks like:

```{r, echo=TRUE}
baseline_model <- rep(mu, nrow(final_holdout_test))
```

RMSE of this baseline model is:

```{r, echo=FALSE}
RMSE_baseline <- RMSE(final_holdout_test$rating, baseline_model)

RMSE_baseline
```
This is a quite poor RMSE, so with the following models we will try to improve this. 


### Regularization

When making a model using both the userId and movieId effect, we can also account for total variability of movie and user effects by adding penalties.
The formula for the penalty would be:

$$
\sum_{i,j} (y_{u,i} - \mu - \alpha_i - \beta_j)^2 + \lambda \sum_{j} \beta_j^2
$$
With the formula for the values of Beta being:

$$
\hat{\beta}_j(\lambda) = \frac{1}{\lambda + n_j} \sum_{i=1}^{n_i} (Y_{i,j} - \mu - \alpha_i)
$$
Before we can use this model, we need to calculate the optimal value for Lambda. We will calculate the RMSE for each value of Lambda and see which Lambda produces the lowest RMSE.

In this piece of code
```{r}
Lambdas <- seq(0, 15, 0.2)

rmse <- sapply(Lambdas, function(Lambda){
 
  mu <- mean(edx$rating)
  
  a_i <- edx %>% 
    group_by(movieId) %>%
    summarize(a_i = sum(rating - mu)/(n()+Lambda))
 
  b_u <- edx %>% 
    left_join(a_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - a_i - mu)/(n()+Lambda))
  
  modelled_ratings <- edx %>% 
    left_join(a_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred_rating = mu + a_i + b_u) %>%
    pull(pred_rating)

  return(RMSE(modelled_ratings, edx$rating))
  
})
```

We can plot the Lambdas against each RMSE
```{r, echo=FALSE}
plot(Lambdas, rmse, type = "b", col = "blue", pch = 19, xlab = "Lambda", ylab = "RMSE",
     main = "RMSE vs Lambda for Regularized Bias")

points(best_Lambda, best_RMSE, col = "red", pch = 19, cex = 2)
text(best_Lambda, best_RMSE, labels = paste0("Lambda=", best_Lambda, "\nRMSE=", 
round(best_RMSE, 4)), pos = 3, col = "red", offset = 1, adj = c(1, 1))

```

In the plot, we can see that the lowest RMSE is with Lambda:
```{r, echo=FALSE}
best_Lambda <- Lambdas[which.min(rmse)]
best_RMSE <- min(rmse)

print(paste("Best Lambda:", best_Lambda))
print(paste("Best RMSE:", best_RMSE))
```


### Matrix factorization

The next model we will use is matrix factorization. 
Before we can apply this method, we will filter the data to ensure we will not run into any issues. We will do this by filtering out any users or movies with less than 50 ratings.





Next, we will convert the data into a matrix. This can be done with the following code:

```{r, echo=TRUE}
rating_matrix <- as.matrix(acast(edx, userId ~ movieId, value.var = "rating"))

rating_matrix <- as(rating_matrix, "realRatingMatrix")
```

The specific matrix factorization method we will use, is singular value decomposition, or SVD for short. 

#### Singular Value Decomposition

We start by setting parameters. Once we have done this, we can create an SVD model. 
```{r, echo=true}
# Set the parameters for SVD
svd_parameters <- list(k = 20)

# Creating a model using SVD
svd_model <- Recommender(rating_matrix, method = "SVD", parameter = svd_parameters)

# Predict ratings for the full dataset
predicted_ratings <- predict(svd_model, rating_matrix, type = "ratings")

# Converting the predictions to a matrix
ratings_matrix <- as(predicted_ratings, "matrix")
```
This model results in this RMSE:
```{r, echo=FALSE}
actual_ratings <- as(rating_matrix, "matrix")
rmse_svd <- sqrt(mean((actual_ratings - predicted_ratings_matrix)^2, na.rm = TRUE))

print(paste("RMSE for SVD without Cross-Validation:", rmse_svd))
```

#### Cross-validation

### Results and evaluation

## Conclusion

## References

https://movielens.org/info/about

Irizarry, Rafael A., “Introduction to Data Science: Data Analysis and Prediction Algorithms in R”
